{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st1W-4PIkaNZ",
        "outputId": "d0e453ed-efbb-451e-97d2-d23df21aeccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-06 07:41:25--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23278 (23K) [text/plain]\n",
            "Saving to: ‘/content/bmi.csv’\n",
            "\n",
            "/content/bmi.csv    100%[===================>]  22.73K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-06 07:41:26 (18.1 MB/s) - ‘/content/bmi.csv’ saved [23278/23278]\n",
            "\n",
            "/content/bmi.csv\n"
          ]
        }
      ],
      "source": [
        "# prompt: get bmi.csv /content/bmi.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv -O /content/bmi.csv\n",
        "!ls /content/bmi.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check the bmi.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv('/content/bmi.csv')\n",
        "\n",
        "# Display some info\n",
        "print(df.info())\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139C1AR1kkrI",
        "outputId": "8a58f2b6-b983-4a11-8dac-de438dc3f92b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 767 entries, 0 to 766\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   6       767 non-null    int64  \n",
            " 1   148     767 non-null    int64  \n",
            " 2   72      767 non-null    int64  \n",
            " 3   35      767 non-null    int64  \n",
            " 4   0       767 non-null    int64  \n",
            " 5   33.6    767 non-null    float64\n",
            " 6   0.627   767 non-null    float64\n",
            " 7   50      767 non-null    int64  \n",
            " 8   1       767 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "None\n",
            "   6  148  72  35    0  33.6  0.627  50  1\n",
            "0  1   85  66  29    0  26.6  0.351  31  0\n",
            "1  8  183  64   0    0  23.3  0.672  32  1\n",
            "2  1   89  66  23   94  28.1  0.167  21  0\n",
            "3  0  137  40  35  168  43.1  2.288  33  1\n",
            "4  5  116  74   0    0  25.6  0.201  30  0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# prompt: data train about this data\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv('/content/bmi.csv')\n",
        "\n",
        "# Print the column names to check if 'Outcome' exists\n",
        "print(df.columns) # This line has been added for debugging\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "# Change 'Outcome' to the actual column name if it's different\n",
        "X = df.drop('Outcome', axis=1)  # Replace 'Outcome' with the correct name if needed\n",
        "y = df['Outcome'] # Replace 'Outcome' with the correct name if needed\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "J0u9zVXyk3ug",
        "outputId": "44fd2d71-c118-429c-b49e-ed9b1212b70b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['6', '148', '72', '35', '0', '33.6', '0.627', '50', '1'], dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Outcome'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-71662aea6f95>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Separate features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Change 'Outcome' to the actual column name if it's different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outcome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace 'Outcome' with the correct name if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Outcome'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Replace 'Outcome' with the correct name if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Outcome'] not found in axis\""
          ]
        }
      ]
    },
    {
      "source": [
        "# prompt: data train about this data\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DyHlorN1k9Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 1) 주어진 bmi.csv 를 이용하여 학습하고, 정확도를 구하세요.\n",
        "# 2)  키 : 160, \t몸무게 :64\n",
        "# 키 :180 \t몸무게 :64\n",
        "# 키 :170 \t몸무게 64 인 사람은\n",
        "# thin/normal/fat 중에 어느 등급인가요?\n",
        "# ** 정확도를 높이는 방법 중 하나는\n",
        "# 숫자 데이터를 0에서 1사이로 변경시는 방법이 있습니다. 이를 정규화라고 부릅니다.\n",
        "# 예)     최대 몸무게를 100이라고 가정하고,     \t각각의 몸무게/100\n",
        "#         최대 키를 200 이라고 가정하고,       \t각각의 키/200\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv('/content/bmi.csv')\n",
        "\n",
        "# Rename columns for clarity (optional but recommended)\n",
        "df.columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "\n",
        "# Normalize numerical features\n",
        "for col in ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']:\n",
        "    df[col] = df[col] / df[col].max()\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict for new data points\n",
        "new_data = pd.DataFrame({\n",
        "    'Pregnancies': [0,0,0],\n",
        "    'Glucose': [160/df['Glucose'].max(), 180/df['Glucose'].max(), 170/df['Glucose'].max()],\n",
        "    'BloodPressure': [64/df['BloodPressure'].max(), 64/df['BloodPressure'].max(), 64/df['BloodPressure'].max()],\n",
        "    'SkinThickness': [0,0,0], # You'll need to provide sensible values here or impute\n",
        "    'Insulin': [0,0,0], # Provide sensible values or impute\n",
        "    'BMI': [64/df['BMI'].max(), 64/df['BMI'].max(),64/df['BMI'].max()],\n",
        "    'DiabetesPedigreeFunction': [0,0,0],  # Provide sensible values or impute\n",
        "    'Age': [0,0,0] # Provide sensible values or impute\n",
        "})\n",
        "\n",
        "\n",
        "predictions = model.predict(new_data)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBy-j4ihkrxI",
        "outputId": "6dacc598-7af8-4415-8be3-4a4d1fbe2108"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8051948051948052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Random Forest Tuning\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "\n",
        "# Gradient Boosting Example\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
        "print(f\"Gradient Boosting Accuracy: {gb_accuracy}\")\n",
        "\n",
        "# Logistic Regression Hyperparameter Tuning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "best_predictions = best_model.predict(X_test)\n",
        "best_accuracy = accuracy_score(y_test, best_predictions)\n",
        "print(f\"Best Logistic Regression Accuracy: {best_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9OD757BlEeg",
        "outputId": "1cba420a-4203-4a24-9f0d-0076feb8fa81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.7857142857142857\n",
            "Gradient Boosting Accuracy: 0.7792207792207793\n",
            "Best Logistic Regression Accuracy: 0.8116883116883117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how can i import to git hub on colab?\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Save the trained model\n",
        "import joblib\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "\n",
        "# Create a zip file containing the model and potentially other relevant files\n",
        "!zip model.zip best_model.pkl\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the zip file to Google Drive\n",
        "!cp /content/model.zip /content/drive/MyDrive/\n",
        "\n",
        "# --- GitHub Integration (using Git) ---\n",
        "# 1. Initialize a Git repository in your Colab environment:\n",
        "!git init\n",
        "\n",
        "# 2. Add the model.zip file to the repository:\n",
        "!git add model.zip\n",
        "\n",
        "# 3. Commit the changes:\n",
        "!git commit -m \"Added trained model\"\n",
        "\n",
        "# 4. Set up your GitHub remote (replace with your actual GitHub repository URL):\n",
        "!git remote add origin <https://github.com/iluv4/dataAnalysis_Study>\n",
        "# 5. Push the changes to GitHub:\n",
        "!git push -u origin main\n",
        "\n",
        "#Important notes:\n",
        "#   * Replace <YOUR_GITHUB_REPOSITORY_URL> with your actual repository.\n",
        "#   * Make sure you have configured your Git credentials (username and email) and have SSH keys set up for seamless authentication with GitHub.  If you don't use SSH keys, you will need to use `git push` with your username and password instead.\n",
        "\n",
        "\n",
        "\n",
        "# Alternative Method using GitHub API:\n",
        "# (Requires installation of PyGithub, see earlier comments)\n",
        "# You might need to install PyGithub\n",
        "# !pip install PyGithub\n",
        "\n",
        "#from github import Github\n",
        "#g = Github(\"<YOUR_GITHUB_ACCESS_TOKEN>\")  # Replace with your GitHub access token\n",
        "#repo = g.get_user().get_repo(\"<YOUR_GITHUB_REPOSITORY_NAME>\")  # Replace with your repository name\n",
        "#with open(\"/content/model.zip\", \"rb\") as f:\n",
        "#    contents = f.read()\n",
        "\n",
        "#try:\n",
        "#    repo.create_file(\"model.zip\", \"Commit message\", contents, branch=\"main\") # Adjust branch if needed\n",
        "#except Exception as e:\n",
        "#    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K9l1nMxsH6h",
        "outputId": "9aa73869-a449-454c-f659-5b86d0646e6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: best_model.pkl (deflated 36%)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reinitialized existing Git repository in /content/.git/\n",
            "[master (root-commit) 44098f1] Added trained model\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 model.zip\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `git remote add origin <https://github.com/iluv4/dataAnalysis_Study>'\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'origin'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:   git config --global user.email \"4mins12@gmail.com\"\n",
        "#   git config --global user.name \"iluv4\"\n",
        "\n",
        "!git config --global user.email \"4mins12@gmail.com\"\n",
        "!git config --global user.name \"iluv4\""
      ],
      "metadata": {
        "id": "rdRlEkN8soT5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: updating: best_model.pkl (deflated 36%)\n",
        "# Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
        "# Reinitialized existing Git repository in /content/.git/\n",
        "# [master (root-commit) 44098f1] Added trained model\n",
        "#  1 file changed, 0 insertions(+), 0 deletions(-)\n",
        "#  create mode 100644 model.zip\n",
        "# /bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
        "# /bin/bash: -c: line 1: `git remote add origin <https://github.com/iluv4/dataAnalysis_Study>'\n",
        "# error: src refspec main does not match any\n",
        "# error: failed to push some refs to 'origin'\n",
        "#   git config --global user.email \"4mins12@gmail.com\"\n",
        "#   git config --global user.name \"iluv4\"\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "\n",
        "# Create a zip file containing the model and potentially other relevant files\n",
        "!zip model.zip best_model.pkl\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the zip file to Google Drive\n",
        "!cp /content/model.zip /content/drive/MyDrive/\n",
        "\n",
        "# --- GitHub Integration (using Git) ---\n",
        "# 1. Initialize a Git repository in your Colab environment:\n",
        "!git init\n",
        "\n",
        "# 2. Add the model.zip file to the repository:\n",
        "!git add model.zip\n",
        "\n",
        "# 3. Commit the changes:\n",
        "!git commit -m \"Added trained model\"\n",
        "\n",
        "# 4. Set up your GitHub remote (replace with your actual GitHub repository URL):\n",
        "!git remote add origin https://github.com/iluv4/dataAnalysis_Study.git\n",
        "\n",
        "# 5. Push the changes to GitHub:\n",
        "!git push -u origin main\n",
        "\n",
        "\n",
        "#Important notes:\n",
        "#   * Make sure you have configured your Git credentials (username and email) and have SSH keys set up for seamless authentication with GitHub.  If you don't use SSH keys, you will need to use `git push` with your username and password instead. You might need to provide your username and password when prompted.\n",
        "\n",
        "!git config --global user.email \"4mins12@gmail.com\"\n",
        "!git config --global user.name \"iluv4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL8LSZ06syPS",
        "outputId": "3003e5a8-80c9-4caa-bff7-a8cd48b38fd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: best_model.pkl (deflated 36%)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reinitialized existing Git repository in /content/.git/\n",
            "[master de24c86] Added trained model\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/iluv4/dataAnalysis_Study.git'\n",
            "\u001b[m"
          ]
        }
      ]
    }
  ]
}